from typing import List, Union, Dict, Any
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
import os
import io
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from scipy import stats
import base64

# LangChain imports
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_experimental.tools import PythonAstREPLTool
from langchain_openai import ChatOpenAI
from langchain_teddynote import logging
from langchain_teddynote.messages import AgentStreamParser, AgentCallbacks

warnings.filterwarnings('ignore')

# TeddyNoteì˜ langsmith ë¡œê¹…
logging.langsmith("Enhanced CSV Agent ì±—ë´‡")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸš€ Advanced CSV Analytics",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    .insight-box {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ì œëª©
st.markdown("""
<div class="main-header">
    <h1>ğŸš€ Advanced CSV Analytics Chatbot</h1>
    <p>AI-powered data analysis with automated insights and interactive visualizations</p>
</div>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    defaults = {
        "messages": [],
        "analysis_history": [],
        "chart_gallery": [],
        "auto_insights": [],
        "processed_files": {},
        "current_analysis": None
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

initialize_session_state()

# ìƒìˆ˜ ì •ì˜
class MessageRole:
    USER = "user"
    ASSISTANT = "assistant"

class MessageType:
    TEXT = "text"
    FIGURE = "figure"
    CODE = "code"
    DATAFRAME = "dataframe"
    PLOTLY = "plotly"
    INSIGHT = "insight"

class AnalysisTemplate:
    EDA = "Exploratory Data Analysis"
    CORRELATION = "Correlation Analysis"
    TIME_SERIES = "Time Series Analysis"
    OUTLIER_DETECTION = "Outlier Detection"
    STATISTICAL_SUMMARY = "Statistical Summary"
    PREDICTIVE_MODELING = "Predictive Modeling"

# ë°ì´í„° ë¶„ì„ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
class DataAnalyzer:
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        self.categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
        self.datetime_cols = []
        self._detect_datetime_columns()

    def _detect_datetime_columns(self):
        """ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ ìë™ ê°ì§€"""
        for col in self.df.columns:
            if self.df[col].dtype == 'object':
                try:
                    pd.to_datetime(self.df[col].head(100), errors='raise')
                    self.datetime_cols.append(col)
                except:
                    pass

    def get_basic_info(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ë°ì´í„° ì •ë³´ ë°˜í™˜"""
        return {
            "shape": self.df.shape,
            "columns": list(self.df.columns),
            "dtypes": self.df.dtypes.to_dict(),
            "missing_values": self.df.isnull().sum().to_dict(),
            "memory_usage": self.df.memory_usage(deep=True).sum(),
            "numeric_columns": self.numeric_cols,
            "categorical_columns": self.categorical_cols,
            "datetime_columns": self.datetime_cols
        }

    def detect_outliers(self, method='iqr') -> Dict[str, List]:
        """ì´ìƒì¹˜ íƒì§€"""
        outliers = {}
        
        for col in self.numeric_cols:
            if method == 'iqr':
                Q1 = self.df[col].quantile(0.25)
                Q3 = self.df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                outlier_indices = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)].index.tolist()
                outliers[col] = outlier_indices
                
        return outliers

    def generate_correlation_insights(self) -> List[str]:
        """ìƒê´€ê´€ê³„ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        if len(self.numeric_cols) < 2:
            return ["ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ë¶€ì¡±í•˜ì—¬ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
        
        corr_matrix = self.df[self.numeric_cols].corr()
        insights = []
        
        # ê°•í•œ ìƒê´€ê´€ê³„ ì°¾ê¸°
        for i, col1 in enumerate(self.numeric_cols):
            for j, col2 in enumerate(self.numeric_cols[i+1:], i+1):
                corr_val = corr_matrix.loc[col1, col2]
                if abs(corr_val) > 0.7:
                    insights.append(f"'{col1}'ê³¼ '{col2}' ê°„ì— {'ê°•í•œ ì–‘ì˜' if corr_val > 0 else 'ê°•í•œ ìŒì˜'} ìƒê´€ê´€ê³„ ë°œê²¬ (r={corr_val:.3f})")
        
        if not insights:
            insights.append("ë³€ìˆ˜ë“¤ ê°„ì— íŠ¹ë³„íˆ ê°•í•œ ìƒê´€ê´€ê³„ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        return insights

    def auto_visualization_suggestions(self) -> List[Dict[str, str]]:
        """ë°ì´í„° íƒ€ì…ì— ë”°ë¥¸ ì‹œê°í™” ì œì•ˆ"""
        suggestions = []
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤
        if len(self.numeric_cols) >= 2:
            suggestions.append({
                "type": "scatter_matrix",
                "description": "ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ê°„ì˜ ì‚°ì ë„ í–‰ë ¬",
                "columns": self.numeric_cols[:5]  # ìµœëŒ€ 5ê°œë§Œ
            })
            
        # ë²”ì£¼í˜• ë³€ìˆ˜ë“¤
        for col in self.categorical_cols[:3]:  # ìµœëŒ€ 3ê°œë§Œ
            if self.df[col].nunique() <= 20:
                suggestions.append({
                    "type": "countplot",
                    "description": f"'{col}' ë³€ìˆ˜ì˜ ë¶„í¬",
                    "column": col
                })
        
        # ì‹œê³„ì—´ ë°ì´í„°
        if self.datetime_cols and self.numeric_cols:
            suggestions.append({
                "type": "time_series",
                "description": "ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„",
                "datetime_col": self.datetime_cols[0],
                "numeric_col": self.numeric_cols[0]
            })
            
        return suggestions

# ì‹œê°í™” ìƒì„±ê¸° í´ë˜ìŠ¤
class VisualizationGenerator:
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.analyzer = DataAnalyzer(df)

    def create_overview_dashboard(self) -> go.Figure:
        """ë°ì´í„° ê°œìš” ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('Data Shape', 'Missing Values', 'Data Types', 'Memory Usage'),
            specs=[[{"type": "indicator"}, {"type": "bar"}],
                   [{"type": "pie"}, {"type": "indicator"}]]
        )
        
        # ë°ì´í„° ëª¨ì–‘
        fig.add_trace(go.Indicator(
            mode="number",
            value=self.df.shape[0] * self.df.shape[1],
            title={"text": f"Total Cells<br>({self.df.shape[0]} Ã— {self.df.shape[1]})"}
        ), row=1, col=1)
        
        # ê²°ì¸¡ê°’
        missing_data = self.df.isnull().sum()
        missing_data = missing_data[missing_data > 0]
        if not missing_data.empty:
            fig.add_trace(go.Bar(
                x=missing_data.index,
                y=missing_data.values,
                name="Missing Values"
            ), row=1, col=2)
        
        # ë°ì´í„° íƒ€ì…
        dtype_counts = self.df.dtypes.value_counts()
        fig.add_trace(go.Pie(
            labels=dtype_counts.index.astype(str),
            values=dtype_counts.values,
            name="Data Types"
        ), row=2, col=1)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory_mb = self.df.memory_usage(deep=True).sum() / 1024 / 1024
        fig.add_trace(go.Indicator(
            mode="gauge+number",
            value=memory_mb,
            title={'text': "Memory Usage (MB)"},
            gauge={'axis': {'range': [None, memory_mb * 2]}}
        ), row=2, col=2)
        
        fig.update_layout(height=600, showlegend=False, title_text="ğŸ“Š Data Overview Dashboard")
        return fig

    def create_correlation_heatmap(self) -> go.Figure:
        """ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ìƒì„±"""
        if len(self.analyzer.numeric_cols) < 2:
            return None
            
        corr_matrix = self.df[self.analyzer.numeric_cols].corr()
        
        fig = go.Figure(data=go.Heatmap(
            z=corr_matrix.values,
            x=corr_matrix.columns,
            y=corr_matrix.columns,
            colorscale='RdBu',
            zmid=0,
            text=np.around(corr_matrix.values, decimals=2),
            texttemplate="%{text}",
            textfont={"size": 10},
            hoverongaps=False
        ))
        
        fig.update_layout(
            title="ğŸ”¥ Correlation Heatmap",
            xaxis_title="Variables",
            yaxis_title="Variables",
            height=500
        )
        
        return fig

    def create_distribution_plots(self) -> List[go.Figure]:
        """ë¶„í¬ í”Œë¡¯ë“¤ ìƒì„±"""
        figures = []
        
        for col in self.analyzer.numeric_cols[:6]:  # ìµœëŒ€ 6ê°œ
            fig = go.Figure()
            
            # íˆìŠ¤í† ê·¸ë¨
            fig.add_trace(go.Histogram(
                x=self.df[col],
                name='Distribution',
                opacity=0.7,
                nbinsx=30
            ))
            
            # ë°•ìŠ¤í”Œë¡¯ ì¶”ê°€
            fig.add_trace(go.Box(
                y=self.df[col],
                name='Box Plot',
                yaxis='y2'
            ))
            
            fig.update_layout(
                title=f"ğŸ“ˆ Distribution of {col}",
                xaxis_title=col,
                yaxis_title="Frequency",
                yaxis2=dict(overlaying='y', side='right', title='Values'),
                height=400
            )
            
            figures.append(fig)
            
        return figures

# ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
def print_messages():
    """ì €ì¥ëœ ë©”ì‹œì§€ë“¤ì„ í™”ë©´ì— ì¶œë ¥"""
    for role, content_list in st.session_state["messages"]:
        with st.chat_message(role):
            for content in content_list:
                if isinstance(content, list) and len(content) == 2:
                    message_type, message_content = content
                    if message_type == MessageType.TEXT:
                        st.markdown(message_content)
                    elif message_type == MessageType.FIGURE:
                        st.pyplot(message_content)
                    elif message_type == MessageType.CODE:
                        with st.expander("ğŸ” ì½”ë“œ ë³´ê¸°", expanded=False):
                            st.code(message_content, language="python")
                    elif message_type == MessageType.DATAFRAME:
                        st.dataframe(message_content, use_container_width=True)
                    elif message_type == MessageType.PLOTLY:
                        st.plotly_chart(message_content, use_container_width=True)
                    elif message_type == MessageType.INSIGHT:
                        st.markdown(f"""
                        <div class="insight-box">
                            <h4>ğŸ’¡ AI Insight</h4>
                            <p>{message_content}</p>
                        </div>
                        """, unsafe_allow_html=True)

def add_message(role: MessageRole, content: List[Union[MessageType, str]]):
    """ë©”ì‹œì§€ ì¶”ê°€"""
    messages = st.session_state["messages"]
    if messages and messages[-1][0] == role:
        messages[-1][1].extend([content])
    else:
        messages.append([role, [content]])

# ìë™ ë¶„ì„ í•¨ìˆ˜ë“¤
def perform_auto_analysis(df: pd.DataFrame) -> Dict[str, Any]:
    """ìë™ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
    analyzer = DataAnalyzer(df)
    viz_gen = VisualizationGenerator(df)
    
    analysis_results = {
        "basic_info": analyzer.get_basic_info(),
        "outliers": analyzer.detect_outliers(),
        "correlation_insights": analyzer.generate_correlation_insights(),
        "viz_suggestions": analyzer.auto_visualization_suggestions(),
        "overview_dashboard": viz_gen.create_overview_dashboard(),
        "correlation_heatmap": viz_gen.create_correlation_heatmap(),
        "distribution_plots": viz_gen.create_distribution_plots()
    }
    
    return analysis_results

def generate_auto_insights(df: pd.DataFrame) -> List[str]:
    """AI ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []
    analyzer = DataAnalyzer(df)
    
    # ê¸°ë³¸ í†µê³„ ì¸ì‚¬ì´íŠ¸
    insights.append(f"ğŸ“Š ë°ì´í„°ì…‹ì€ {df.shape[0]:,}ê°œì˜ í–‰ê³¼ {df.shape[1]}ê°œì˜ ì—´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # ê²°ì¸¡ê°’ ì¸ì‚¬ì´íŠ¸
    missing_count = df.isnull().sum().sum()
    if missing_count > 0:
        insights.append(f"âš ï¸ ì´ {missing_count:,}ê°œì˜ ê²°ì¸¡ê°’ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„° ì „ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        insights.append("âœ… ê²°ì¸¡ê°’ì´ ì—†ëŠ” ê¹¨ë—í•œ ë°ì´í„°ì…ë‹ˆë‹¤.")
    
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì¸ì‚¬ì´íŠ¸
    if analyzer.numeric_cols:
        insights.append(f"ğŸ”¢ {len(analyzer.numeric_cols)}ê°œì˜ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ìˆì–´ í†µê³„ ë¶„ì„ê³¼ ì˜ˆì¸¡ ëª¨ë¸ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ì™œë„ ë¶„ì„
        for col in analyzer.numeric_cols[:3]:
            skewness = df[col].skew()
            if abs(skewness) > 1:
                insights.append(f"ğŸ“ˆ '{col}' ë³€ìˆ˜ëŠ” {'ìš°í¸í–¥' if skewness > 0 else 'ì¢Œí¸í–¥'}ëœ ë¶„í¬ë¥¼ ë³´ì…ë‹ˆë‹¤ (ì™œë„: {skewness:.2f})")
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì‚¬ì´íŠ¸
    if analyzer.categorical_cols:
        high_cardinality_cols = [col for col in analyzer.categorical_cols if df[col].nunique() > 50]
        if high_cardinality_cols:
            insights.append(f"ğŸ·ï¸ {len(high_cardinality_cols)}ê°œì˜ ë³€ìˆ˜ê°€ ë†’ì€ cardinalityë¥¼ ê°€ì§‘ë‹ˆë‹¤: {', '.join(high_cardinality_cols[:3])}")
    
    return insights

# ì½œë°± í•¨ìˆ˜ë“¤
def tool_callback(tool) -> None:
    """ë„êµ¬ ì‹¤í–‰ ì½œë°±"""
    if tool_name := tool.get("tool"):
        if tool_name == "python_repl_ast":
            tool_input = tool.get("tool_input", {})
            query = tool_input.get("query")
            if query:
                with st.status("ğŸ” ë¶„ì„ ì¤‘...", expanded=True) as status:
                    add_message(MessageRole.ASSISTANT, [MessageType.CODE, query])

                    if "df" in st.session_state:
                        # í™˜ê²½ ì„¤ì •
                        st.session_state["python_tool"].locals.update({
                            "pd": pd, "sns": sns, "plt": plt, "px": px, "go": go,
                            "np": np, "st": st
                        })
                        
                        try:
                            result = st.session_state["python_tool"].invoke({"query": query})
                            
                            # ê²°ê³¼ ì²˜ë¦¬
                            if isinstance(result, pd.DataFrame):
                                st.dataframe(result, use_container_width=True)
                                add_message(MessageRole.ASSISTANT, [MessageType.DATAFRAME, result])
                            
                            # ì‹œê°í™” ì²˜ë¦¬
                            if "plt.show" in query or "st.pyplot" in query:
                                fig = plt.gcf()
                                st.pyplot(fig)
                                add_message(MessageRole.ASSISTANT, [MessageType.FIGURE, fig])
                                # ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬ì— ì¶”ê°€
                                st.session_state["chart_gallery"].append({
                                    "type": "matplotlib",
                                    "figure": fig,
                                    "timestamp": datetime.now(),
                                    "query": query
                                })
                                
                            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ", state="complete", expanded=False)
                            
                        except Exception as e:
                            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            return
                    else:
                        st.error("âŒ ë°ì´í„°í”„ë ˆì„ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

def observation_callback(observation) -> None:
    """ê´€ì°° ê²°ê³¼ ì½œë°±"""
    if "observation" in observation:
        obs = observation["observation"]
        if isinstance(obs, str) and "Error" in obs:
            st.error(f"âŒ {obs}")

def result_callback(result: str) -> None:
    """ê²°ê³¼ ì½œë°±"""
    pass

def create_agent(dataframe, selected_model="gpt-4o-mini"):
    """ê°•í™”ëœ ì—ì´ì „íŠ¸ ìƒì„±"""
    openai_key = os.environ.get("OPENAI_API_KEY", "")
    if not openai_key:
        st.error("âŒ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        return None
        
    enhanced_prefix = """
    You are an expert data scientist and analyst with deep knowledge in:
    - Statistical analysis and hypothesis testing
    - Data visualization best practices
    - Machine learning and predictive modeling
    - Data preprocessing and cleaning techniques
    
    Available libraries: pandas, numpy, matplotlib, seaborn, plotly, sklearn, scipy
    
    CRITICAL INSTRUCTIONS:
    1. Always use 'df' as the main DataFrame variable (DO NOT recreate it)
    2. For matplotlib: Use fig, ax = plt.subplots() and st.pyplot(fig)
    3. For plotly: Use st.plotly_chart(fig, use_container_width=True)
    4. Prefer seaborn and plotly for modern, beautiful visualizations
    5. Use English for plot titles and labels
    6. Apply consistent styling: white background, muted colors, no grid
    7. Always explain your analysis approach and findings
    8. Suggest next steps or additional analyses when appropriate
    
    Dataset info:
    - Shape: {shape}
    - Columns: {columns}
    - Numeric columns: {numeric_cols}
    - Categorical columns: {cat_cols}
    
    Respond in Korean for explanations, but use English for code comments and plot labels.
    """.format(
        shape=dataframe.shape,
        columns=list(dataframe.columns),
        numeric_cols=dataframe.select_dtypes(include=[np.number]).columns.tolist(),
        cat_cols=dataframe.select_dtypes(include=['object']).columns.tolist()
    )
    
    return create_pandas_dataframe_agent(
        ChatOpenAI(model=selected_model, temperature=0.1, api_key=openai_key),
        dataframe,
        verbose=False,
        agent_type="tool-calling",
        allow_dangerous_code=True,
        prefix=enhanced_prefix,
        max_iterations=5,
        early_stopping_method="generate"
    )

def ask(query):
    """ì§ˆë¬¸ ì²˜ë¦¬"""
    if "agent" in st.session_state:
        st.chat_message("user").write(query)
        add_message(MessageRole.USER, [MessageType.TEXT, query])
        
        agent = st.session_state["agent"]
        response = agent.stream({"input": query})
        ai_answer = ""
        
        parser_callback = AgentCallbacks(tool_callback, observation_callback, result_callback)
        stream_parser = AgentStreamParser(parser_callback)
        
        with st.chat_message("assistant"):
            for step in response:
                stream_parser.process_agent_steps(step)
                if "output" in step:
                    ai_answer += step["output"]
            
            if ai_answer:
                st.write(ai_answer)
                add_message(MessageRole.ASSISTANT, [MessageType.TEXT, ai_answer])

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.markdown("## ğŸ”§ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    st.markdown("### ğŸ”‘ OpenAI API Key")
    user_api_key = st.text_input("API Key", type="password", help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    
    if user_api_key:
        os.environ["OPENAI_API_KEY"] = user_api_key
        st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    st.markdown("---")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    st.markdown("### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ", 
        type=["csv"], 
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )
    
    # ë¶„ì„ í…œí”Œë¦¿ ì„ íƒ
    st.markdown("### ğŸ“‹ ë¶„ì„ í…œí”Œë¦¿")
    selected_template = st.selectbox(
        "ë¶„ì„ ìœ í˜• ì„ íƒ",
        [
            AnalysisTemplate.EDA,
            AnalysisTemplate.CORRELATION,
            AnalysisTemplate.TIME_SERIES,
            AnalysisTemplate.OUTLIER_DETECTION,
            AnalysisTemplate.STATISTICAL_SUMMARY,
            AnalysisTemplate.PREDICTIVE_MODELING
        ]
    )
    
    # ë²„íŠ¼ë“¤
    col1, col2 = st.columns(2)
    with col1:
        apply_btn = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary")
    with col2:
        clear_btn = st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”")
    
    auto_analysis_btn = st.button("ğŸ¤– ìë™ ë¶„ì„", help="AIê°€ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤")
    
    st.markdown("---")
    
    # ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬
    if st.session_state["chart_gallery"]:
        st.markdown("### ğŸ–¼ï¸ ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬")
        st.write(f"ìƒì„±ëœ ì°¨íŠ¸: {len(st.session_state['chart_gallery'])}ê°œ")
        
        if st.button("ê°¤ëŸ¬ë¦¬ ë³´ê¸°"):
            st.session_state["show_gallery"] = True

# ë©”ì¸ ì½˜í…ì¸  ì˜ì—­
if clear_btn:
    st.session_state["messages"] = []
    st.session_state["chart_gallery"] = []
    st.session_state["auto_insights"] = []
    st.rerun()

# íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘
if apply_btn:
    if not user_api_key:
        st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not uploaded_files:
        st.warning("âš ï¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        # ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬
        for uploaded_file in uploaded_files:
            try:
                df = pd.read_csv(uploaded_file)
                file_name = uploaded_file.name
                
                st.session_state["processed_files"][file_name] = df
                
                # ë©”ì¸ DataFrame ì„¤ì • (ì²« ë²ˆì§¸ íŒŒì¼)
                if len(st.session_state["processed_files"]) == 1:
                    st.session_state["df"] = df
                    st.session_state["python_tool"] = PythonAstREPLTool()
                    st.session_state["python_tool"].locals.update({
                        "df": df, "pd": pd, "sns": sns, "plt": plt, 
                        "px": px, "go": go, "np": np
                    })
                    st.session_state["agent"] = create_agent(df)
                
                st.success(f"âœ… '{file_name}' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"âŒ '{uploaded_file.name}' íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# ìë™ ë¶„ì„ ìˆ˜í–‰
if auto_analysis_btn and "df" in st.session_state:
    with st.spinner("ğŸ¤– AIê°€ ë°ì´í„°ë¥¼ ìë™ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        df = st.session_state["df"]
        
        # ìë™ ë¶„ì„ ìˆ˜í–‰
        analysis_results = perform_auto_analysis(df)
        auto_insights = generate_auto_insights(df)
        
        # ê²°ê³¼ í‘œì‹œ
        st.markdown("## ğŸ¤– AI ìë™ ë¶„ì„ ê²°ê³¼")
        
        # ê¸°ë³¸ ì •ë³´ ëŒ€ì‹œë³´ë“œ
        if analysis_results["overview_dashboard"]:
            st.plotly_chart(analysis_results["overview_dashboard"], use_container_width=True)
            add_message(MessageRole.ASSISTANT, [MessageType.PLOTLY, analysis_results["overview_dashboard"]])
        
        # ìë™ ì¸ì‚¬ì´íŠ¸
        st.markdown("### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
        for insight in auto_insights:
            st.markdown(f"- {insight}")
            add_message(MessageRole.ASSISTANT, [MessageType.INSIGHT, insight])
        
        # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        if analysis_results["correlation_heatmap"]:
            st.markdown("### ğŸ”¥ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„")
            st.plotly_chart(analysis_results["correlation_heatmap"], use_container_width=True)
            add_message(MessageRole.ASSISTANT, [MessageType.PLOTLY, analysis_results["correlation_heatmap"]])
        
        # ìƒê´€ê´€ê³„ ì¸ì‚¬ì´íŠ¸
        st.markdown("### ğŸ“Š ìƒê´€ê´€ê³„ ë¶„ì„")
        for insight in analysis_results["correlation_insights"]:
            st.markdown(f"- {insight}")
        
        # ë¶„í¬ í”Œë¡¯ë“¤
        if analysis_results["distribution_plots"]:
            st.markdown("### ğŸ“ˆ ë³€ìˆ˜ ë¶„í¬ ë¶„ì„")
            cols = st.columns(2)
            for i, fig in enumerate(analysis_results["distribution_plots"][:4]):  # ìµœëŒ€ 4ê°œë§Œ
                with cols[i % 2]:
                    st.plotly_chart(fig, use_container_width=True)
                    add_message(MessageRole.ASSISTANT, [MessageType.PLOTLY, fig])
        
        # ì´ìƒì¹˜ íƒì§€ ê²°ê³¼
        outliers = analysis_results["outliers"]
        if any(len(indices) > 0 for indices in outliers.values()):
            st.markdown("### âš ï¸ ì´ìƒì¹˜ íƒì§€ ê²°ê³¼")
            outlier_summary = []
            for col, indices in outliers.items():
                if len(indices) > 0:
                    outlier_summary.append(f"'{col}': {len(indices)}ê°œ ì´ìƒì¹˜ ë°œê²¬")
            
            for summary in outlier_summary:
                st.markdown(f"- {summary}")
        
        # ì‹œê°í™” ì œì•ˆ
        st.markdown("### ğŸ¨ ì¶”ì²œ ì‹œê°í™”")
        viz_suggestions = analysis_results["viz_suggestions"]
        for suggestion in viz_suggestions[:3]:  # ìµœëŒ€ 3ê°œë§Œ
            st.markdown(f"- **{suggestion['type']}**: {suggestion['description']}")
        
        st.session_state["current_analysis"] = analysis_results
        st.success("âœ… ìë™ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì±„íŒ…ìœ¼ë¡œ ë” ìì„¸í•œ ë¶„ì„ì„ ìš”ì²­í•´ë³´ì„¸ìš”.")

# í…œí”Œë¦¿ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰
def execute_template_analysis(template: str, df: pd.DataFrame):
    """í…œí”Œë¦¿ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰"""
    if template == AnalysisTemplate.EDA:
        query = """
        ë°ì´í„°ì…‹ì— ëŒ€í•œ ì™„ì „í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”. 
        ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. ê¸°ë³¸ í†µê³„ ìš”ì•½
        2. ê²°ì¸¡ê°’ ë¶„ì„
        3. ë°ì´í„° ë¶„í¬ ì‹œê°í™”
        4. ì£¼ìš” ë³€ìˆ˜ë“¤ì˜ ê´€ê³„ ë¶„ì„
        """
    elif template == AnalysisTemplate.CORRELATION:
        query = """
        ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ íˆíŠ¸ë§µ ìƒì„±
        2. ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ë³€ìˆ˜ ìŒ ì‹ë³„
        3. ìƒê´€ê´€ê³„ì˜ ì‹¤ë¬´ì  ì˜ë¯¸ í•´ì„
        """
    elif template == AnalysisTemplate.TIME_SERIES:
        query = """
        ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        1. ì‹œê°„ì— ë”°ë¥¸ íŠ¸ë Œë“œ ë¶„ì„
        2. ê³„ì ˆì„± íŒ¨í„´ íƒì§€
        3. ì´ìƒì¹˜ ë° ë³€í™”ì  ì‹ë³„
        """
    elif template == AnalysisTemplate.OUTLIER_DETECTION:
        query = """
        ë°ì´í„°ì˜ ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. í†µê³„ì  ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ ì‹ë³„
        2. ì´ìƒì¹˜ ì‹œê°í™”
        3. ì´ìƒì¹˜ê°€ ë¶„ì„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í‰ê°€
        """
    elif template == AnalysisTemplate.STATISTICAL_SUMMARY:
        query = """
        ìƒì„¸í•œ í†µê³„ ìš”ì•½ì„ ì œê³µí•´ì£¼ì„¸ìš”:
        1. ê¸°ìˆ í†µê³„ëŸ‰ ê³„ì‚°
        2. ë¶„í¬ì˜ ì •ê·œì„± ê²€ì •
        3. ë³€ìˆ˜ë³„ íŠ¹ì„± ë¶„ì„
        """
    elif template == AnalysisTemplate.PREDICTIVE_MODELING:
        query = """
        ì˜ˆì¸¡ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        1. ì ì ˆí•œ íƒ€ê²Ÿ ë³€ìˆ˜ ì‹ë³„
        2. ê°„ë‹¨í•œ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
        3. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        """
    else:
        query = "ë°ì´í„°ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
    
    return query

# ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬ í‘œì‹œ
if st.session_state.get("show_gallery", False):
    st.markdown("## ğŸ–¼ï¸ ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬")
    
    if st.session_state["chart_gallery"]:
        cols = st.columns(2)
        for i, chart_info in enumerate(st.session_state["chart_gallery"]):
            with cols[i % 2]:
                st.markdown(f"**ìƒì„± ì‹œê°„**: {chart_info['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                if chart_info["type"] == "matplotlib":
                    st.pyplot(chart_info["figure"])
                with st.expander("ì½”ë“œ ë³´ê¸°"):
                    st.code(chart_info["query"], language="python")
                st.markdown("---")
    else:
        st.info("ì•„ì§ ìƒì„±ëœ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    if st.button("ê°¤ëŸ¬ë¦¬ ë‹«ê¸°"):
        st.session_state["show_gallery"] = False
        st.rerun()

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.markdown("## ğŸ’¬ ë°ì´í„° ë¶„ì„ ì±„íŒ…")

# ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼ë“¤
if "df" in st.session_state:
    st.markdown("### ğŸš€ ë¹ ë¥¸ ë¶„ì„")
    quick_questions = [
        "ë°ì´í„° ìš”ì•½ í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
        "ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”", 
        "ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ë¥¼ ì‹œê°í™”í•´ì£¼ì„¸ìš”",
        "ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ì˜ ë¹ˆë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
        "ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"
    ]
    
    cols = st.columns(3)
    for i, question in enumerate(quick_questions):
        with cols[i % 3]:
            if st.button(question, key=f"quick_{i}"):
                ask(question)

# ë©”ì‹œì§€ ì¶œë ¥
print_messages()

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë°ì´í„°ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”! ì˜ˆ: 'ë§¤ì¶œ ë°ì´í„°ì˜ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”'")

if user_input:
    ask(user_input)

# í…œí”Œë¦¿ ë¶„ì„ ì‹¤í–‰
if "df" in st.session_state and selected_template:
    template_query = execute_template_analysis(selected_template, st.session_state["df"])
    
    if st.sidebar.button("í…œí”Œë¦¿ ë¶„ì„ ì‹¤í–‰"):
        ask(template_query)

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.8em;">
    ğŸš€ Enhanced CSV Analytics Chatbot | Powered by OpenAI GPT-4 & Streamlit<br>
    ğŸ’¡ AI ìë™ ë¶„ì„, ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”, ìŠ¤ë§ˆíŠ¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
</div>
""", unsafe_allow_html=True)

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (ì„ íƒì‚¬í•­)
if st.session_state.get("df") is not None:
    with st.expander("ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´"):
        df = st.session_state["df"]
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("í–‰ ìˆ˜", f"{df.shape[0]:,}")
        with col2:
            st.metric("ì—´ ìˆ˜", df.shape[1])
        with col3:
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
        with col4:
            st.metric("ê²°ì¸¡ê°’", f"{df.isnull().sum().sum():,}")
        
        # ì»¬ëŸ¼ ì •ë³´
        st.markdown("**ì»¬ëŸ¼ ì •ë³´**")
        col_info = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': df.columns,
            'ë°ì´í„°íƒ€ì…': df.dtypes.values,
            'ê²°ì¸¡ê°’': df.isnull().sum().values,
            'ê³ ìœ ê°’ìˆ˜': [df[col].nunique() for col in df.columns]
        })
        st.dataframe(col_info, use_container_width=True)
