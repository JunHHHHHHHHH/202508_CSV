from typing import List, Union
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import streamlit as st
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_experimental.tools import PythonAstREPLTool
from langchain_openai import ChatOpenAI
from langchain_teddynote import logging
from langchain_teddynote.messages import AgentStreamParser, AgentCallbacks

# TeddyNote Î°úÍ∑∏
logging.langsmith("CSV Agent Ï±óÎ¥á")

# Streamlit Ïï± Ï†úÎ™©
st.title("CSV Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï±óÎ¥á üí¨")

# ÏÑ∏ÏÖò ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "df_list" not in st.session_state:
    st.session_state["df_list"] = []
if "file_names" not in st.session_state:
    st.session_state["file_names"] = []
if "agent" not in st.session_state:
    st.session_state["agent"] = None
if "python_tool" not in st.session_state:
    st.session_state["python_tool"] = None

# ÏÉÅÏàò ÏÑ†Ïñ∏

class MessageRole:
    USER = "user"
    ASSISTANT = "assistant"

class MessageType:
    TEXT = "text"
    FIGURE = "figure"
    CODE = "code"
    DATAFRAME = "dataframe"

# Î©îÏãúÏßÄ Ï∂úÎ†• Ìï®Ïàò
def print_messages():
    for role, content_list in st.session_state["messages"]:
        with st.chat_message(role):
            for content in content_list:
                if isinstance(content, list):
                    message_type, message_content = content
                    if message_type == MessageType.TEXT:
                        st.markdown(message_content)
                    elif message_type == MessageType.FIGURE:
                        st.pyplot(message_content)
                    elif message_type == MessageType.CODE:
                        with st.expander("ÏΩîÎìú Î≥¥Í∏∞"):
                            st.code(message_content, language="python")
                    elif message_type == MessageType.DATAFRAME:
                        st.dataframe(message_content)
                    else:
                        raise ValueError(f"Ïïå Ïàò ÏóÜÎäî ÏΩòÌÖêÏ∏† Ïú†Ìòï: {content}")

# Î©îÏãúÏßÄ Ï∂îÍ∞Ä Ìï®Ïàò
def add_message(role: MessageRole, content: List[Union[MessageType, str]]):
    messages = st.session_state["messages"]
    if messages and messages[-1][0] == role:
        messages[-1][1].extend([content])
    else:
        messages.append([role, [content]])

# API ÌÇ§ ÏûÖÎ†• Î∞è ÌååÏùº ÏóÖÎ°úÎìú UI
with st.sidebar:
    st.markdown("üîë **OpenAI API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî**")
    user_api_key = st.text_input("OpenAI API Key", type="password")
    clear_btn = st.button("ÎåÄÌôî Ï¥àÍ∏∞Ìôî")
    uploaded_files = st.file_uploader("CSV ÌååÏùºÎì§ÏùÑ ÏóÖÎ°úÎìú Ìï¥Ï£ºÏÑ∏Ïöî (Îã§Ï§ë ÏóÖÎ°úÎìú ÏßÄÏõê)", type=["csv"], accept_multiple_files=True)
    pre_process_option = st.checkbox("Í≤∞Ï∏°Ïπò Ï†úÍ±∞", value=False)
    outlier_detect_option = st.checkbox("Ïù¥ÏÉÅÏπò ÏûêÎèô ÌÉêÏßÄ", value=False)
    apply_btn = st.button("Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÏãúÏûë")

# API ÌÇ§ ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï
if user_api_key:
    os.environ["OPENAI_API_KEY"] = user_api_key

# Ï¥àÍ∏∞Ìôî Î≤ÑÌäº
if clear_btn:
    st.session_state["messages"] = []
    st.session_state["df_list"] = []
    st.session_state["file_names"] = []
    st.session_state["agent"] = None
    st.session_state["python_tool"] = None
    st.experimental_rerun()

# Ï†ÑÏ≤òÎ¶¨: Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ Î∞è Ïù¥ÏÉÅÏπò ÌÉêÏßÄ
def preprocess_df(df, drop_na=False, outlier_detect=False):
    info_msgs = []
    # Í≤∞Ï∏°Ïπò Ï†úÍ±∞
    if drop_na:
        before_shape = df.shape
        df = df.dropna()
        info_msgs.append(f"Í≤∞Ï∏°Ïπò Ï†úÍ±∞ ÏàòÌñâ. {before_shape} ‚Üí {df.shape}")
    # Ïù¥ÏÉÅÏπò ÌÉêÏßÄ - z-score Í∏∞Î∞ò
    if outlier_detect:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) == 0:
            info_msgs.append("Ïà´ÏûêÌòï Ïª¨ÎüºÏù¥ ÏóÜÏñ¥ Ïù¥ÏÉÅÏπò ÌÉêÏßÄÎ•º ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
            return df, info_msgs
        from scipy.stats import zscore
        z_scores = np.abs(zscore(df[numeric_cols], nan_policy='omit'))
        threshold = 3
        outliers = (z_scores > threshold).any(axis=1)
        num_outliers = outliers.sum()
        info_msgs.append(f"Ïù¥ÏÉÅÏπòÎ°ú Í∞êÏßÄÎêú Ìñâ Ïàò: {num_outliers}")
        df_clean = df.loc[~outliers]
        info_msgs.append(f"Ïù¥ÏÉÅÏπò Ï†úÍ±∞ ÌõÑ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {df_clean.shape}")
        return df_clean, info_msgs
    return df, info_msgs

# ÏûêÎèô Îç∞Ïù¥ÌÑ∞ Í∞úÏöî Ï∂úÎ†•
def auto_data_overview(df, name=None):
    st.subheader(f"{name or 'Îç∞Ïù¥ÌÑ∞'} Í∏∞Î≥∏ Í∞úÏöî Î∞è ÌÜµÍ≥Ñ")
    st.write(f"ÌñâÎ†¨ ÌÅ¨Í∏∞: {df.shape}")
    st.write("Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ:")
    st.write(df.dtypes)
    st.write("Í≤∞Ï∏°Ïπò Í∞úÏàò:")
    st.write(df.isnull().sum())
    st.write("Í∏∞Î≥∏ Í∏∞Ïà†ÌÜµÍ≥Ñ:")
    st.write(df.describe(include='all'))
    st.markdown("---")

# ÏûêÎèô Î≥ÄÏàòÎ≥Ñ ÏãúÍ∞ÅÌôî Ï∂îÏ≤ú Î∞è Ï∂úÎ†• (Plotly)
def auto_visualization(df, name="Îç∞Ïù¥ÌÑ∞"):
    st.subheader(f"{name} ÏûêÎèô ÏãúÍ∞ÅÌôî")
    for col in df.columns:
        # ÏàòÏπòÌòï
        if pd.api.types.is_numeric_dtype(df[col]):
            fig = px.histogram(df, x=col, nbins=30, title=f"{col} Î∂ÑÌè¨ (Histogram)")
        # ÎÇ†ÏßúÌòï
        elif pd.api.types.is_datetime64_any_dtype(df[col]):
            # Ïà´ÏûêÌòï Ïà´Ïûê Ïª¨Îüº ÏÑ†ÌÉù (ÏµúÏ¥à Î∞úÍ≤¨)
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                y_col = numeric_cols[0]
                fig = px.line(df.sort_values(by=col), x=col, y=y_col, title=f"{col} vs {y_col} (Line Plot)")
            else:
                continue
        # Î≤îÏ£ºÌòï
        else:
            counts = df[col].value_counts().reset_index()
            counts.columns = [col, "count"]
            fig = px.bar(counts, x=col, y="count", title=f"{col} ÎπàÎèÑ (Bar Chart)")
        st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")

# Îã§Ï§ë ÌååÏùº ÎπÑÍµê Í∞ÑÎã® ÏòàÏãú: shape, Ïª¨ÎüºÎ™Ö Ï∞®Ïù¥ ÏãúÍ∞ÅÌôî
def multi_file_summary(df_list, file_names):
    st.subheader("ÏóÖÎ°úÎìúÎêú Îç∞Ïù¥ÌÑ∞ ÌååÏùº ÏöîÏïΩ Î∞è ÎπÑÍµê")
    summary = []
    for i, df in enumerate(df_list):
        summary.append({
            "ÌååÏùºÎ™Ö": file_names[i],
            "Ìñâ(row)": df.shape[0],
            "Ïó¥(column)": df.shape[1],
            "Ïª¨ÎüºÎ™Ö": ", ".join(df.columns)
        })
    df_summary = pd.DataFrame(summary)
    st.table(df_summary)

    # Ïª¨ÎüºÎ™Ö ÎπÑÍµê
    all_columns = [set(df.columns) for df in df_list]
    common_cols = set.intersection(*all_columns)
    unique_cols = [set(df.columns) - common_cols for df in df_list]
    
    st.write(f"Í≥µÌÜµ Ïª¨Îüº: {sorted(common_cols)}")
    for i, uc in enumerate(unique_cols):
        st.write(f"{file_names[i]} Í≥†Ïú† Ïª¨Îüº: {sorted(uc)}")
    st.markdown("---")

# Langchain Agent ÏÉùÏÑ±
def create_agent(dataframe, selected_model="gpt-4.1-mini"):
    openai_key = os.environ.get("OPENAI_API_KEY", "")
    if not openai_key:
        st.error("OpenAI API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî (ÏÇ¨Ïù¥ÎìúÎ∞î)")
        return None
    return create_pandas_dataframe_agent(
        ChatOpenAI(model=selected_model, temperature=0, api_key=openai_key),
        dataframe,
        verbose=False,
        agent_type="tool-calling",
        allow_dangerous_code=True,
        prefix=(
            "You are a professional data analyst and expert in Pandas. "
            "You must use Pandas DataFrame(`df`) to answer user's request. "
            "\n\n[IMPORTANT] DO NOT create or overwrite the `df` variable in your code. \n\n"
            "If you are willing to generate visualization code, you must use fig, ax = plt.subplots() and st.pyplot(fig) to show the figure in Streamlit. "
            "Prefer seaborn code for visualization, but matplotlib is also allowed."
            "\n\n\n"
            "- [IMPORTANT] Use `English` for your visualization title and labels."
            "- Please use palette='muted' for seaborn (not cmap), and for matplotlib use a valid colormap (for example, 'viridis')."
            "- White background, and no grid for your visualization."
            "\nRecommend to set cmap, palette parameter for seaborn plot if applicable. "
            "The language of final answer should be Korean."
            "\n\n###\n\n\n"
            "If user asks with columns that are not listed in `df.columns`, you may refer to the most similar columns listed below.\n"
        ),
    )

# AgentÏö© ÏΩúÎ∞± Ìï®Ïàò (Í∏∞Ï°¥ ÎèôÏùº)
def tool_callback(tool) -> None:
    if tool_name := tool.get("tool"):
        if tool_name == "python_repl_ast":
            tool_input = tool.get("tool_input", {})
            query = tool_input.get("query")
            if query:
                df_in_result = None
                with st.status("Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...", expanded=True) as status:
                    add_message(MessageRole.ASSISTANT, [MessageType.CODE, query])
                    if "df" in st.session_state:
                        sns.set_theme(style="white")
                        st.session_state["python_tool"].locals["pd"] = pd
                        st.session_state["python_tool"].locals["sns"] = sns
                        st.session_state["python_tool"].locals["plt"] = plt
                        try:
                            result = st.session_state["python_tool"].invoke({"query": query})
                        except Exception as e:
                            st.error(f"Ïò§Î•ò Î∞úÏÉù: {e}")
                            return
                        if isinstance(result, pd.DataFrame):
                            df_in_result = result
                        status.update(label="ÏΩîÎìú Ï∂úÎ†•", state="complete", expanded=False)
                        if df_in_result is not None:
                            st.dataframe(df_in_result)
                            add_message(MessageRole.ASSISTANT, [MessageType.DATAFRAME, df_in_result])
                        if "plt.show" in query or "st.pyplot" in query:
                            fig = plt.gcf()
                            st.pyplot(fig)
                            add_message(MessageRole.ASSISTANT, [MessageType.FIGURE, fig])
                        return result
                    else:
                        st.error("Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏù¥ Ï†ïÏùòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. CSV ÌååÏùºÏùÑ Î®ºÏ†Ä ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî.")
                        return

def observation_callback(observation) -> None:
    if "observation" in observation:
        obs = observation["observation"]
        if isinstance(obs, str) and "Error" in obs:
            st.error(obs)
            st.session_state["messages"][-1][1].clear()

def result_callback(result: str) -> None:
    pass

# ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ Ï≤òÎ¶¨ Ìï®Ïàò
def ask(query):
    if "agent" in st.session_state and st.session_state["agent"]:
        st.chat_message("user").write(query)
        add_message(MessageRole.USER, [MessageType.TEXT, query])
        agent = st.session_state["agent"]
        response = agent.stream({"input": query})
        ai_answer = ""
        parser_callback = AgentCallbacks(tool_callback, observation_callback, result_callback)
        stream_parser = AgentStreamParser(parser_callback)
        with st.chat_message("assistant"):
            for step in response:
                stream_parser.process_agent_steps(step)
                if "output" in step:
                    ai_answer += step["output"]
            st.write(ai_answer)
            add_message(MessageRole.ASSISTANT, [MessageType.TEXT, ai_answer])

# ÏóÖÎ°úÎìú ÌõÑ Ï≤òÎ¶¨ Î∞è Î∂ÑÏÑù ÏãúÏûë
if apply_btn:
    if not user_api_key:
        st.warning("OpenAI API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
    elif not uploaded_files or len(uploaded_files) == 0:
        st.warning("ÌååÏùºÏùÑ ÏóÖÎ°úÎìú Ìï¥Ï£ºÏÑ∏Ïöî.")
    else:
        # Ïó¨Îü¨ ÌååÏùº Ï≤òÎ¶¨
        dfs = []
        names = []
        preprocess_infos = []
        for file in uploaded_files:
            df_load = pd.read_csv(file)
            df_processed, info_msgs = preprocess_df(df_load, drop_na=pre_process_option, outlier_detect=outlier_detect_option)
            dfs.append(df_processed)
            names.append(file.name)
            preprocess_infos.append((file.name, info_msgs))

        st.session_state["df_list"] = dfs
        st.session_state["file_names"] = names
        
        # Í∏∞Î≥∏ Í∞úÏöî & Ï†ÑÏ≤òÎ¶¨ ÏïàÎÇ¥
        for name, msgs in preprocess_infos:
            if msgs:
                st.write(f"**[{name}] Ï†ÑÏ≤òÎ¶¨ Ï†ïÎ≥¥:**")
                for msg in msgs:
                    st.write("- " + msg)

        # Îã§Ï§ë ÌååÏùº ÏöîÏïΩ Î∞è ÎπÑÍµê
        multi_file_summary(dfs, names)

        # Í∞Å ÌååÏùºÎ≥Ñ ÏûêÎèô Î∂ÑÏÑù Î∞è ÏãúÍ∞ÅÌôî
        for i, df_single in enumerate(dfs):
            auto_data_overview(df_single, names[i])
            auto_visualization(df_single, names[i])

        # AgentÎäî Ï≤´Î≤àÏß∏ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Í∏∞Ï§Ä ÏÉùÏÑ± (Ï∂îÌõÑ Î≥ëÌï©ÎèÑ Í∞ÄÎä•)
        st.session_state["python_tool"] = PythonAstREPLTool()
        st.session_state["python_tool"].locals["pd"] = pd
        st.session_state["python_tool"].locals["sns"] = sns
        st.session_state["python_tool"].locals["plt"] = plt
        st.session_state["python_tool"].locals["df"] = dfs[0]  # Í∏∞Î≥∏ df ÏßÄÏ†ï
        st.session_state["agent"] = create_agent(dfs[0])

        st.success("Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§. Í∂ÅÍ∏àÌïú ÎÇ¥Ïö©ÏùÑ Î¨ºÏñ¥Î≥¥ÏÑ∏Ïöî!")

# Î©îÏãúÏßÄ Ï∂úÎ†•
print_messages()

# ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Ï≤òÎ¶¨
user_input = st.chat_input("Í∂ÅÍ∏àÌïú ÎÇ¥Ïö©ÏùÑ Î¨ºÏñ¥Î≥¥ÏÑ∏Ïöî!")
if user_input:
    ask(user_input)
    print_messages()
