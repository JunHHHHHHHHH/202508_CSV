from typing import List, Union
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import streamlit as st
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_experimental.tools import PythonAstREPLTool
from langchain_openai import ChatOpenAI
from langchain_teddynote import logging
from langchain_teddynote.messages import AgentStreamParser, AgentCallbacks

# TeddyNote ë¡œê·¸
logging.langsmith("CSV Agent ì±—ë´‡")

# Streamlit ì•± ì œëª©
st.title("CSV ë°ì´í„° ë¶„ì„ ì±—ë´‡ ğŸ’¬")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "df_list" not in st.session_state:
    st.session_state["df_list"] = []
if "file_names" not in st.session_state:
    st.session_state["file_names"] = []
if "agent" not in st.session_state:
    st.session_state["agent"] = None
if "python_tool" not in st.session_state:
    st.session_state["python_tool"] = None

# ìƒìˆ˜ ì„ ì–¸

class MessageRole:
    USER = "user"
    ASSISTANT = "assistant"

class MessageType:
    TEXT = "text"
    FIGURE = "figure"
    CODE = "code"
    DATAFRAME = "dataframe"

# ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
def print_messages():
    for role, content_list in st.session_state["messages"]:
        with st.chat_message(role):
            for content in content_list:
                if isinstance(content, list):
                    message_type, message_content = content
                    if message_type == MessageType.TEXT:
                        st.markdown(message_content)
                    elif message_type == MessageType.FIGURE:
                        st.pyplot(message_content)
                    elif message_type == MessageType.CODE:
                        with st.expander("ì½”ë“œ ë³´ê¸°"):
                            st.code(message_content, language="python")
                    elif message_type == MessageType.DATAFRAME:
                        st.dataframe(message_content)
                    else:
                        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì½˜í…ì¸  ìœ í˜•: {content}")

# ë©”ì‹œì§€ ì¶”ê°€ í•¨ìˆ˜
def add_message(role: MessageRole, content: List[Union[MessageType, str]]):
    messages = st.session_state["messages"]
    if messages and messages[-1][0] == role:
        messages[-1][1].extend([content])
    else:
        messages.append([role, [content]])

# API í‚¤ ì…ë ¥ ë° íŒŒì¼ ì—…ë¡œë“œ UI
with st.sidebar:
    st.markdown("ğŸ”‘ **OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”**")
    user_api_key = st.text_input("OpenAI API Key", type="password")
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")
    uploaded_files = st.file_uploader("CSV íŒŒì¼ë“¤ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš” (ë‹¤ì¤‘ ì—…ë¡œë“œ ì§€ì›)", type=["csv"], accept_multiple_files=True)
    pre_process_option = st.checkbox("ê²°ì¸¡ì¹˜ ì œê±°", value=False)
    outlier_detect_option = st.checkbox("ì´ìƒì¹˜ ìë™ íƒì§€", value=False)
    apply_btn = st.button("ë°ì´í„° ë¶„ì„ ì‹œì‘")

# API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
if user_api_key:
    os.environ["OPENAI_API_KEY"] = user_api_key

# ì´ˆê¸°í™” ë²„íŠ¼
if clear_btn:
    st.session_state["messages"] = []
    st.session_state["df_list"] = []
    st.session_state["file_names"] = []
    st.session_state["agent"] = None
    st.session_state["python_tool"] = None
    st.experimental_rerun()

# ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ì´ìƒì¹˜ íƒì§€
def preprocess_df(df, drop_na=False, outlier_detect=False):
    info_msgs = []
    # ê²°ì¸¡ì¹˜ ì œê±°
    if drop_na:
        before_shape = df.shape
        df = df.dropna()
        info_msgs.append(f"ê²°ì¸¡ì¹˜ ì œê±° ìˆ˜í–‰. {before_shape} â†’ {df.shape}")
    # ì´ìƒì¹˜ íƒì§€ - z-score ê¸°ë°˜
    if outlier_detect:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) == 0:
            info_msgs.append("ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ì–´ ì´ìƒì¹˜ íƒì§€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return df, info_msgs
        from scipy.stats import zscore
        z_scores = np.abs(zscore(df[numeric_cols], nan_policy='omit'))
        threshold = 3
        outliers = (z_scores > threshold).any(axis=1)
        num_outliers = outliers.sum()
        info_msgs.append(f"ì´ìƒì¹˜ë¡œ ê°ì§€ëœ í–‰ ìˆ˜: {num_outliers}")
        df_clean = df.loc[~outliers]
        info_msgs.append(f"ì´ìƒì¹˜ ì œê±° í›„ ë°ì´í„° í¬ê¸°: {df_clean.shape}")
        return df_clean, info_msgs
    return df, info_msgs

# ìë™ ë°ì´í„° ê°œìš” ì¶œë ¥
def auto_data_overview(df, name=None):
    st.subheader(f"{name or 'ë°ì´í„°'} ê¸°ë³¸ ê°œìš” ë° í†µê³„")
    st.write(f"í–‰ë ¬ í¬ê¸°: {df.shape}")
    st.write("ë°ì´í„° íƒ€ì…:")
    st.write(df.dtypes)
    st.write("ê²°ì¸¡ì¹˜ ê°œìˆ˜:")
    st.write(df.isnull().sum())
    st.write("ê¸°ë³¸ ê¸°ìˆ í†µê³„:")
    st.write(df.describe(include='all'))
    st.markdown("---")

# ìë™ ë³€ìˆ˜ë³„ ì‹œê°í™” ì¶”ì²œ ë° ì¶œë ¥ (Plotly)
def auto_visualization(df, name="ë°ì´í„°"):
    st.subheader(f"{name} ìë™ ì‹œê°í™”")
    for col in df.columns:
        # ìˆ˜ì¹˜í˜•
        if pd.api.types.is_numeric_dtype(df[col]):
            fig = px.histogram(df, x=col, nbins=30, title=f"{col} ë¶„í¬ (Histogram)")
        # ë‚ ì§œí˜•
        elif pd.api.types.is_datetime64_any_dtype(df[col]):
            # ìˆ«ìí˜• ìˆ«ì ì»¬ëŸ¼ ì„ íƒ (ìµœì´ˆ ë°œê²¬)
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                y_col = numeric_cols[0]
                fig = px.line(df.sort_values(by=col), x=col, y=y_col, title=f"{col} vs {y_col} (Line Plot)")
            else:
                continue
        # ë²”ì£¼í˜•
        else:
            counts = df[col].value_counts().reset_index()
            counts.columns = [col, "count"]
            fig = px.bar(counts, x=col, y="count", title=f"{col} ë¹ˆë„ (Bar Chart)")
        st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")

# ë‹¤ì¤‘ íŒŒì¼ ë¹„êµ ê°„ë‹¨ ì˜ˆì‹œ: shape, ì»¬ëŸ¼ëª… ì°¨ì´ ì‹œê°í™”
def multi_file_summary(df_list, file_names):
    st.subheader("ì—…ë¡œë“œëœ ë°ì´í„° íŒŒì¼ ìš”ì•½ ë° ë¹„êµ")
    summary = []
    for i, df in enumerate(df_list):
        summary.append({
            "íŒŒì¼ëª…": file_names[i],
            "í–‰(row)": df.shape[0],
            "ì—´(column)": df.shape[1],
            "ì»¬ëŸ¼ëª…": ", ".join(df.columns)
        })
    df_summary = pd.DataFrame(summary)
    st.table(df_summary)

    # ì»¬ëŸ¼ëª… ë¹„êµ
    all_columns = [set(df.columns) for df in df_list]
    common_cols = set.intersection(*all_columns)
    unique_cols = [set(df.columns) - common_cols for df in df_list]
    
    st.write(f"ê³µí†µ ì»¬ëŸ¼: {sorted(common_cols)}")
    for i, uc in enumerate(unique_cols):
        st.write(f"{file_names[i]} ê³ ìœ  ì»¬ëŸ¼: {sorted(uc)}")
    st.markdown("---")

# Langchain Agent ìƒì„±
def create_agent(dataframe, selected_model="gpt-4.1-mini"):
    openai_key = os.environ.get("OPENAI_API_KEY", "")
    if not openai_key:
        st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì‚¬ì´ë“œë°”)")
        return None
    return create_pandas_dataframe_agent(
        ChatOpenAI(model=selected_model, temperature=0, api_key=openai_key),
        dataframe,
        verbose=False,
        agent_type="tool-calling",
        allow_dangerous_code=True,
        prefix=(
            "You are a professional data analyst and expert in Pandas. "
            "You must use Pandas DataFrame(`df`) to answer user's request. "
            "\n\n[IMPORTANT] DO NOT create or overwrite the `df` variable in your code. \n\n"
            "If you are willing to generate visualization code, you must use fig, ax = plt.subplots() and st.pyplot(fig) to show the figure in Streamlit. "
            "Prefer seaborn code for visualization, but matplotlib is also allowed."
            "\n\n\n"
            "- [IMPORTANT] Use `English` for your visualization title and labels."
            "- Please use palette='muted' for seaborn (not cmap), and for matplotlib use a valid colormap (for example, 'viridis')."
            "- White background, and no grid for your visualization."
            "\nRecommend to set cmap, palette parameter for seaborn plot if applicable. "
            "The language of final answer should be Korean."
            "\n\n###\n\n\n"
            "If user asks with columns that are not listed in `df.columns`, you may refer to the most similar columns listed below.\n"
        ),
    )

# Agentìš© ì½œë°± í•¨ìˆ˜ (ê¸°ì¡´ ë™ì¼)
def tool_callback(tool) -> None:
    if tool_name := tool.get("tool"):
        if tool_name == "python_repl_ast":
            tool_input = tool.get("tool_input", {})
            query = tool_input.get("query")
            if query:
                df_in_result = None
                with st.status("ë°ì´í„° ë¶„ì„ ì¤‘...", expanded=True) as status:
                    add_message(MessageRole.ASSISTANT, [MessageType.CODE, query])
                    if "df" in st.session_state:
                        sns.set_theme(style="white")
                        st.session_state["python_tool"].locals["pd"] = pd
                        st.session_state["python_tool"].locals["sns"] = sns
                        st.session_state["python_tool"].locals["plt"] = plt
                        try:
                            result = st.session_state["python_tool"].invoke({"query": query})
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                            return
                        if isinstance(result, pd.DataFrame):
                            df_in_result = result
                        status.update(label="ì½”ë“œ ì¶œë ¥", state="complete", expanded=False)
                        if df_in_result is not None:
                            st.dataframe(df_in_result)
                            add_message(MessageRole.ASSISTANT, [MessageType.DATAFRAME, df_in_result])
                        if "plt.show" in query or "st.pyplot" in query:
                            fig = plt.gcf()
                            st.pyplot(fig)
                            add_message(MessageRole.ASSISTANT, [MessageType.FIGURE, fig])
                        return result
                    else:
                        st.error("ë°ì´í„°í”„ë ˆì„ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                        return

def observation_callback(observation) -> None:
    if "observation" in observation:
        obs = observation["observation"]
        if isinstance(obs, str) and "Error" in obs:
            st.error(obs)
            st.session_state["messages"][-1][1].clear()

def result_callback(result: str) -> None:
    pass

# ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def ask(query):
    if "agent" in st.session_state and st.session_state["agent"]:
        st.chat_message("user").write(query)
        add_message(MessageRole.USER, [MessageType.TEXT, query])
        agent = st.session_state["agent"]
        response = agent.stream({"input": query})
        ai_answer = ""
        parser_callback = AgentCallbacks(tool_callback, observation_callback, result_callback)
        stream_parser = AgentStreamParser(parser_callback)
        with st.chat_message("assistant"):
            for step in response:
                stream_parser.process_agent_steps(step)
                if "output" in step:
                    ai_answer += step["output"]
            st.write(ai_answer)
            add_message(MessageRole.ASSISTANT, [MessageType.TEXT, ai_answer])

# ì—…ë¡œë“œ í›„ ì²˜ë¦¬ ë° ë¶„ì„ ì‹œì‘
if apply_btn:
    if not user_api_key:
        st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not uploaded_files or len(uploaded_files) == 0:
        st.warning("íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
    else:
        # ì—¬ëŸ¬ íŒŒì¼ ì²˜ë¦¬
        dfs = []
        names = []
        preprocess_infos = []
        for file in uploaded_files:
            df_load = pd.read_csv(file)
            df_processed, info_msgs = preprocess_df(df_load, drop_na=pre_process_option, outlier_detect=outlier_detect_option)
            dfs.append(df_processed)
            names.append(file.name)
            preprocess_infos.append((file.name, info_msgs))

        st.session_state["df_list"] = dfs
        st.session_state["file_names"] = names
        
        # ê¸°ë³¸ ê°œìš” & ì „ì²˜ë¦¬ ì•ˆë‚´
        for name, msgs in preprocess_infos:
            if msgs:
                st.write(f"**[{name}] ì „ì²˜ë¦¬ ì •ë³´:**")
                for msg in msgs:
                    st.write("- " + msg)

        # ë‹¤ì¤‘ íŒŒì¼ ìš”ì•½ ë° ë¹„êµ
        multi_file_summary(dfs, names)

        # ê° íŒŒì¼ë³„ ìë™ ë¶„ì„ ë° ì‹œê°í™”
        for i, df_single in enumerate(dfs):
            auto_data_overview(df_single, names[i])
            auto_visualization(df_single, names[i])

        # AgentëŠ” ì²«ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ ê¸°ì¤€ ìƒì„± (ì¶”í›„ ë³‘í•©ë„ ê°€ëŠ¥)
        st.session_state["python_tool"] = PythonAstREPLTool()
        st.session_state["python_tool"].locals["pd"] = pd
        st.session_state["python_tool"].locals["sns"] = sns
        st.session_state["python_tool"].locals["plt"] = plt
        st.session_state["python_tool"].locals["df"] = dfs[0]  # ê¸°ë³¸ df ì§€ì •
        st.session_state["agent"] = create_agent(dfs[0])

        st.success("ë°ì´í„° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ë©”ì‹œì§€ ì¶œë ¥
print_messages()

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
if user_input:
    ask(user_input)
    print_messages()
